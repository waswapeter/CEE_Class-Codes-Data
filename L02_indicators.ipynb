{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOvur6LrB+oZ1W64xKtmcZ7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/m-zaniolo/CEE690-ESAA/blob/main/L02_indicators.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lab 2 - indicators"
      ],
      "metadata": {
        "id": "_v76eZwKcCcj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load data and packages."
      ],
      "metadata": {
        "id": "_gVwMLxocSUf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "plt.rcParams['figure.dpi'] = 600\n",
        "\n",
        "url = 'https://raw.githubusercontent.com/m-zaniolo/CEE690-ESAA/main/data/'\n",
        "inflow = np.loadtxt(url + 'inflow.txt', delimiter='\\t') #m3/s\n"
      ],
      "metadata": {
        "id": "wv-jfLPNcsKd",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pandas offers convenient functionalities to handle dates."
      ],
      "metadata": {
        "id": "Guab8wAVr-n-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# generate date array\n",
        "# Generate the full date range from January 1, 2001, to December 31, 2015\n",
        "date_range = pd.date_range(start='2001-01-01', end='2015-12-31', freq='D')\n",
        "\n",
        "# Filter out all February 29 instances\n",
        "date_range = date_range[~((date_range.month == 2) & (date_range.day == 29))]\n"
      ],
      "metadata": {
        "id": "-2g_UGaLko7f",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "some useful functions:\n",
        " `convolve`, `reshape`, `concatenate`\n"
      ],
      "metadata": {
        "id": "YmcGcvIwfgPH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the window size for convolution\n",
        "window_size = 7\n",
        "\n",
        "# Calculate the rolling window average\n",
        "rolling_avg = np.convolve(inflow, np.ones(window_size)/window_size, mode='valid')\n",
        "\n",
        "#note: the convolution creates a shorter rolling average array. Namely, len(rolling_avg) = len(inflow) - (window_size - 1)\n",
        "print( 'inflow timeseries length: ' + str( len(inflow) )  )\n",
        "print( 'inflow rolling average length: ' + str( len(rolling_avg) )  )\n",
        "print(np.ones(window_size)/window_size)"
      ],
      "metadata": {
        "id": "p2sb2dKCfkZy",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for odd window sizes, assign values to the center of the rolling window by concatenating NaNs\n",
        "semi_window = int( (window_size - 1)/2 )\n",
        "concatenate_values = np.full(( semi_window,), np.nan)\n",
        "rolling_avg_c = np.concatenate( [concatenate_values, rolling_avg, concatenate_values] )\n",
        "\n",
        "# reshape to annual values\n",
        "Ny = int( len(inflow) / 365 )\n",
        "rolling_annual = np.reshape(rolling_avg_c, (Ny, 365))  #shape is in (nrows, ncolumns). Elements are arranged in rows\n",
        "\n",
        "print(rolling_annual) # matrix of dimension Nyears x 365 days where each value is the rolling weekly average."
      ],
      "metadata": {
        "id": "7TfK2DaMni0q",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We can plot this matrix:\n",
        "# Set up the plot\n",
        "fig, ax = plt.subplots(figsize=(12, 6))\n",
        "\n",
        "# Create a colormap\n",
        "cmap = plt.get_cmap('viridis')\n",
        "\n",
        "# Plot each year with a different color from the colormap\n",
        "for i in range(Ny):\n",
        "    color = cmap(i / Ny)\n",
        "    ax.plot(rolling_annual[i], color=color, label=f'Year {i+1}')\n",
        "\n",
        "# Add labels and title\n",
        "ax.set_xlabel('Day of the Year')\n",
        "ax.set_ylabel('Inflow [m3/s]')\n",
        "ax.set_title('Inflow Over Years with Gradient Colors')\n",
        "\n",
        "# Show the legend\n",
        "ax.legend(loc='upper right')\n",
        "\n",
        "# Display the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "iNJnUmOLlGZQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##_Environment: indicators of hydrological alteration_\n",
        "\n",
        "We consider the inflow as the unaltered flow in the location, and calculate how different reservoir operation strategies impact a representative IHA.\n"
      ],
      "metadata": {
        "id": "bciL1ABtcwpi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "How much does the considered release strategies alter the annual 3-day peak flow?\n",
        "\n"
      ],
      "metadata": {
        "id": "bcmiOIgi8Tyx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "window_size = 3\n",
        "rolling = np.convolve(inflow, np.ones(window_size)/window_size, mode='valid')\n",
        "concatenate_values = np.full(( int( (window_size - 1)/2 ),), np.nan)\n",
        "rolling_avg_c = np.concatenate( [concatenate_values, rolling, concatenate_values] )\n",
        "rolling_annual = np.reshape(rolling_avg_c, (Ny, 365))  #shape is in (nrows, ncolumns). Elements are arranged in rows\n",
        "\n",
        "max3day = np.nanmax(rolling_annual, axis=1) # using the function np.max would return NaNs for the first and last year\n",
        "ref_max3days = np.mean(max3day) #average 3-day peak\n",
        "\n",
        "plt.plot(max3day)\n",
        "# Plot the average maximum value as a dashed horizontal line\n",
        "plt.axhline(y=ref_max3days, color='r', linestyle='--')\n",
        "\n",
        "\n",
        "plt.title('Undisturbed annual maximum 3-day flow')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "VG1Q8kTjcwId",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's see how different release alternatives modify this IHA"
      ],
      "metadata": {
        "id": "fcD-Qckw9wPg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load release alternatives and set dates\n",
        "r1 = np.loadtxt(url + 'release1.txt', delimiter='\\t') #m3/s\n",
        "r2 = np.loadtxt(url + 'release2.txt', delimiter='\\t') #m3/s\n",
        "r3 = np.loadtxt(url + 'release3.txt', delimiter='\\t') #m3/s\n",
        "r4 = np.loadtxt(url + 'release4.txt', delimiter='\\t') #m3/s\n",
        "\n",
        "# let's have a look at these\n",
        "plt.plot(date_range, inflow, color = 'b', linestyle='-')\n",
        "plt.plot(date_range, r1, color = 'r', linestyle='--')\n",
        "plt.plot(date_range, r2, color = 'r', linestyle='-.')\n",
        "plt.plot(date_range, r3, color = 'r', linestyle=':')\n",
        "plt.plot(date_range, r4, color = 'r', linestyle='-')\n",
        "plt.ylabel('Flow [m3/s]')\n"
      ],
      "metadata": {
        "id": "k-1Iv0hC-B5l",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate IHA for different release strategies\n",
        "# Since it requires a few lines of code, we can create a function\n",
        "\n",
        "def peakAnnualFlow(flow, window_size):\n",
        "\n",
        "  rolling = np.convolve(flow, np.ones(window_size)/window_size, mode='valid')\n",
        "  concatenate_values = np.full(( int( (window_size - 1)/2 ),), np.nan)\n",
        "  rolling_avg_c = np.concatenate( [concatenate_values, rolling, concatenate_values] )\n",
        "  rolling_annual = np.reshape(rolling_avg_c, (Ny, 365))\n",
        "\n",
        "  return np.nanmax(rolling_annual, axis=1)\n",
        "\n",
        "\n",
        "max3day_r1 = peakAnnualFlow(r1, window_size)\n",
        "max3day_r2 = peakAnnualFlow(r2, window_size)\n",
        "max3day_r3 = peakAnnualFlow(r3, window_size)\n",
        "max3day_r4 = peakAnnualFlow(r4, window_size)\n",
        "\n",
        "# Let's visualize how these release strategies alter the natural 3-day peak flow\n",
        "\n",
        "plt.plot( max3day, color = 'b', linestyle='-', label = 'undisturbed')\n",
        "plt.plot( max3day_r1, color = 'r', linestyle='--', label = 'r1')\n",
        "plt.plot( max3day_r2, color = 'r', linestyle='-.', label = 'r2')\n",
        "plt.plot( max3day_r3, color = 'r', linestyle=':', label = 'r3')\n",
        "plt.plot( max3day_r4, color = 'r', linestyle='-', label = 'r4')\n",
        "plt.legend()\n",
        "plt.ylabel('Flow [m3/s]')\n",
        "\n",
        "plt.title('Annual Maximum 3-day flow')"
      ],
      "metadata": {
        "id": "aISPVU-VBsTS",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "S5gFtu0yBrsO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "All strategies significantly alter the undisturbed indicator. In order to rank policies from worst to best we need to aggregate these time series.\n",
        "\n",
        "How? For instance, we can use the absolute deviation wrt to the mean.\n",
        "\n"
      ],
      "metadata": {
        "id": "XLVMkZqVApXM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#mean of the IHA for the time period\n",
        "undisturbed_m3d_avg = np.mean(max3day)\n",
        "r1_m3d_avg = np.mean(max3day_r1)\n",
        "r2_m3d_avg = np.mean(max3day_r2)\n",
        "r3_m3d_avg = np.mean(max3day_r3)\n",
        "r4_m3d_avg = np.mean(max3day_r4)\n",
        "\n",
        "Jenvironment1 = [np.abs(undisturbed_m3d_avg - r1_m3d_avg),\n",
        "                       np.abs(undisturbed_m3d_avg - r2_m3d_avg),\n",
        "                       np.abs(undisturbed_m3d_avg - r3_m3d_avg),\n",
        "                       np.abs(undisturbed_m3d_avg - r4_m3d_avg)]\n",
        "\n",
        "labels = ['r1', 'r2', 'r3', 'r4']\n",
        "id = np.argmin(Jenvironment1)\n",
        "\n",
        "print('the release strategy that minimize the deviation wrt to the considered IHA is: ')\n",
        "print(labels[id])\n",
        "\n",
        "# Creating the bar plot\n",
        "plt.bar(labels, Jenvironment1)\n",
        "plt.title('Average annual deviation from average annual 3-day peak flow')\n",
        "\n"
      ],
      "metadata": {
        "id": "M7UWgMxfBCsY",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Another relevant indicator may be the average flow in August, when recession agriculture is performed."
      ],
      "metadata": {
        "id": "mMR7tXy9_RBm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "august_start_day = 213\n",
        "august_end_day = 243\n",
        "\n",
        "#reshape to annual matrix\n",
        "annual = np.reshape(inflow, (Ny , 365))\n",
        "august = annual[:, august_start_day:august_end_day+1]\n",
        "\n",
        "target_August_flow = np.mean(august)\n",
        "print('Target average annual August flow: ' + str(target_August_flow) + 'm3/s')\n",
        "\n",
        "aug_r1 = np.reshape(r1, (Ny, 365))[:, august_start_day:august_end_day+1]\n",
        "aug_r2 = np.reshape(r2, (Ny, 365))[:, august_start_day:august_end_day+1]\n",
        "aug_r3 = np.reshape(r3, (Ny, 365))[:, august_start_day:august_end_day+1]\n",
        "aug_r4 = np.reshape(r4, (Ny, 365))[:, august_start_day:august_end_day+1]\n",
        "\n",
        "Jenvironment2 = [ np.abs(np.mean( aug_r1 ) - target_August_flow) ,\n",
        "                  np.abs(np.mean( aug_r2 ) - target_August_flow) ,\n",
        "                  np.abs(np.mean( aug_r3 ) - target_August_flow) ,\n",
        "                  np.abs(np.mean( aug_r4 ) - target_August_flow) ]\n"
      ],
      "metadata": {
        "id": "AR4RlUyw_QhT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "fOxzPyktlvmY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##_Energy: hydropower production_\n"
      ],
      "metadata": {
        "id": "fxb-i7NfIF9b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "hydropower production can be calculated as:\n",
        "\n",
        "\n",
        "hp = level * release * effic * ρ * g (W)\n",
        "\n",
        "where ρ = 1000 kg/m3\n",
        "g = 9.81 m/s2  acceleration of gravity.\n",
        "\n",
        "To convert values to [MW] we divide by 10e6\n",
        "\n",
        "Let's load the level timeseries we calculated last time"
      ],
      "metadata": {
        "id": "m38zD8mQJYnG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "l1 = np.loadtxt(url + 'level1.txt', delimiter='\\t')[1:]\n",
        "l2 = np.loadtxt(url + 'level2.txt', delimiter='\\t')[1:]\n",
        "l3 = np.loadtxt(url + 'level3.txt', delimiter='\\t')[1:]\n",
        "l4 = np.loadtxt(url + 'level4.txt', delimiter='\\t')[1:]\n"
      ],
      "metadata": {
        "id": "DBbeqTFej7XO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "timseries of hydropower production:"
      ],
      "metadata": {
        "id": "3Vg46t6kkYmv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "efficiency = 0.9 # in realty, turbine efficiency is more complicated than a simple constant\n",
        "g = 9.81\n",
        "d = 1000\n",
        "\n",
        "hp1 = l1*r1*efficiency*g*d/10e6\n",
        "hp2 = l2*r2*efficiency*g*d/10e6\n",
        "hp3 = l3*r3*efficiency*g*d/10e6\n",
        "hp4 = l4*r4*efficiency*g*d/10e6\n"
      ],
      "metadata": {
        "id": "4FIO1qJPkYOx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aggregate hydropower production time series into a single indicator:"
      ],
      "metadata": {
        "id": "Dr0-v201FN0t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# option 1: average annual production\n",
        "\n",
        "Jenergy1 = [ np.mean(hp1)*365, np.mean(hp2)*365, np.mean(hp3)*365, np.mean(hp4)*365]\n",
        "\n",
        "# option 2: firm energy - minimum annual production\n",
        "annual_hp1 = np.reshape(hp1, (Ny, 365) )\n",
        "sum_annual_hp1 = np.sum( annual_hp1 , axis = 1)\n",
        "\n",
        "sum_annual_hp2 = np.sum( np.reshape(hp2, (Ny, 365) ) , axis = 1) #consolidating in a single line of code\n",
        "sum_annual_hp3 = np.sum( np.reshape(hp3, (Ny, 365) ) , axis = 1)\n",
        "sum_annual_hp4 = np.sum( np.reshape(hp4, (Ny, 365) ) , axis = 1)\n",
        "\n",
        "Jenergy2 = [ np.min(sum_annual_hp1), np.min(sum_annual_hp2), np.min(sum_annual_hp3), np.min(sum_annual_hp4) ]\n",
        "\n",
        "#visualize both indicators\n",
        "x = np.arange(len(labels))  # the label locations\n",
        "width = 0.35  # the width of the bars\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "rects1 = ax.bar(x - width/2, Jenergy1, width, label='Avg annual HP production')\n",
        "rects2 = ax.bar(x + width/2, Jenergy2, width, label='Firm Energy')\n",
        "\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(labels)\n",
        "ax.legend()"
      ],
      "metadata": {
        "id": "IbU_CgfHk6yz",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "nL2CsobClt71"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "##_Food: agricultural production_\n",
        "\n"
      ],
      "metadata": {
        "id": "JMjkzoMoM0b4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can evaluate this in terms of level of satisfaction of an agricultural demand. A squared formulation allows to penalize large concentrated deficit"
      ],
      "metadata": {
        "id": "dxyhvlH5M_uz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "D = 80 #assume daily constant water demand in m3/s\n",
        "N = 2  # crop dependent\n",
        "# calculate timeseries of agricultural deficit (ad)\n",
        "\n",
        "ad_r1 = (np.maximum(D - r1, 0 )) ** N\n",
        "ad_r2 = (np.maximum(D - r2, 0 )) ** N\n",
        "ad_r3 = (np.maximum(D - r3, 0 )) ** N\n",
        "ad_r4 = (np.maximum(D - r4, 0 )) ** N\n",
        "\n",
        "# aggregate time series.\n",
        "\n",
        "#Option 1: avg annual deficit\n",
        "Jfood1 = [ np.mean(ad_r1)*365, np.mean(ad_r2)*365, np.mean(ad_r3)*365, np.mean(ad_r4)*365 ]\n",
        "\n",
        "# Option 2: worst year\n",
        "sum_annual_ad1 = np.sum( np.reshape(ad_r1, (Ny, 365) ) , axis = 1)\n",
        "sum_annual_ad2 = np.sum( np.reshape(ad_r2, (Ny, 365) ) , axis = 1)\n",
        "sum_annual_ad3 = np.sum( np.reshape(ad_r3, (Ny, 365) ) , axis = 1)\n",
        "sum_annual_ad4 = np.sum( np.reshape(ad_r4, (Ny, 365) ) , axis = 1)\n",
        "\n",
        "Jfood2 = [ np.max(sum_annual_ad1), np.max(sum_annual_ad2), np.max(sum_annual_ad3), np.max(sum_annual_ad4) ]\n",
        "\n",
        "labels = ['r1', 'r2', 'r3', 'r4']\n",
        "x = np.arange(len(labels))  # the label locations\n",
        "width = 0.35  # the width of the bars\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "rects1 = ax.bar(x - width/2, Jfood1, width, label='Avg annual Deficit')\n",
        "rects2 = ax.bar(x + width/2, Jfood2, width, label='Worst Year')\n",
        "\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(labels)\n",
        "ax.legend()"
      ],
      "metadata": {
        "id": "oEqpNuOBN7qE",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## _Flood indicators_\n",
        "\n",
        "for example, flood on lake shores when lake level > dam height"
      ],
      "metadata": {
        "id": "q38DU59n1y_j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dam_height = 232.1 #m\n",
        "\n",
        "# average number of flood days per year\n",
        "flood_days_1 = l1>= dam_height\n",
        "flood_days_2 = l2>= dam_height\n",
        "flood_days_3 = l3>= dam_height\n",
        "flood_days_4 = l4>= dam_height\n",
        "\n",
        "# aggregate as annual average\n",
        "\n",
        "H = len(l1)\n",
        "Ny = H/365\n",
        "Jflood1 = [np.sum(flood_days_1)/Ny, np.sum(flood_days_2)/Ny, np.sum(flood_days_3)/Ny, np.sum(flood_days_4)/Ny] #average annual flood days\n",
        "\n",
        "\n",
        "# flood magnitude\n",
        "flood_magn_1 = l1[flood_days_1] - dam_height\n",
        "flood_magn_2 = l2[flood_days_2] - dam_height\n",
        "flood_magn_3 = l3[flood_days_3] - dam_height\n",
        "flood_magn_4 = l4[flood_days_4] - dam_height\n",
        "\n",
        "# aggregate as annual average\n",
        "Jflood2 = [np.sum(flood_magn_1)/Ny, np.sum(flood_magn_2)/Ny, np.sum(flood_magn_3)/Ny, np.sum(flood_magn_4)/Ny] #average annual flood magnitude\n",
        "\n",
        "plt.subplot(2,1,1)\n",
        "plt.bar(labels, Jflood1)\n",
        "\n",
        "\n",
        "plt.subplot(2,1,2)\n",
        "plt.bar(labels, Jflood2)\n",
        "\n"
      ],
      "metadata": {
        "id": "d2axHIL5Pr_s",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "# Which release policy is best?\n",
        "... it depends of what indicators we care about. Let's make some plots to highlight tradeoffs:\n",
        "\n",
        "_The tradeoff between 2 indicators are well represented by a scatterplot:_"
      ],
      "metadata": {
        "id": "xujUDNBf6oMl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Set figure size\n",
        "plt.figure(figsize=(4, 4))\n",
        "\n",
        "# Create scatter plot\n",
        "x = Jfood1\n",
        "y = Jflood1\n",
        "\n",
        "# Create scatter plot\n",
        "plt.scatter(x, y)\n",
        "\n",
        "# Label each point\n",
        "for i, label in enumerate(labels):\n",
        "    plt.annotate(label, (x[i], y[i]), textcoords=\"offset points\", xytext=(5, 5), ha='center')\n",
        "\n",
        "# Label the x and y axes\n",
        "plt.xlabel('Food indicator (min)')\n",
        "plt.ylabel('Flood indicator (min)')\n",
        "\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Set figure size\n",
        "plt.figure(figsize=(4, 4))\n",
        "\n",
        "# Create scatter plot\n",
        "w = Jenergy1\n",
        "z = Jenvironment1\n",
        "\n",
        "# Create scatter plot\n",
        "plt.scatter(w, z)\n",
        "\n",
        "# Label each point\n",
        "for i, label in enumerate(labels):\n",
        "    plt.annotate(label, (w[i], z[i]), textcoords=\"offset points\", xytext=(5, 5), ha='center')\n",
        "\n",
        "# Label the x and y axes\n",
        "plt.xlabel('HP production (max)')\n",
        "plt.ylabel('IHA deviation (min)')\n",
        "\n",
        "# Display the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "6p1vH5p92lza",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "_The tradeoff between 3 indicators can be represented with a 3D scatterplot, or a 2D scatterplot with the addition of size or color:_"
      ],
      "metadata": {
        "id": "_zPyWr1hcTwX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "import numpy as np\n",
        "\n",
        "fig = plt.figure(figsize=(18, 6))\n",
        "\n",
        "# First panel: 3D scatter plot\n",
        "ax1 = fig.add_subplot(131, projection='3d')\n",
        "sc1 = ax1.scatter(x, y, z)\n",
        "ax1.set_xlabel('Food (min)')\n",
        "ax1.set_ylabel('Flood (min)')\n",
        "ax1.set_zlabel('Environment (min)')\n",
        "for i, label in enumerate(labels):\n",
        "    ax1.text(x[i], y[i], z[i], label)\n",
        "ax1.set_title('3D Scatter Plot')\n",
        "\n",
        "# Second panel: 2D scatter plot with marker size for the third dimension\n",
        "ax2 = fig.add_subplot(132)\n",
        "sc2 = ax2.scatter(x, y, s=z)  # scale marker size by z\n",
        "ax2.set_xlabel('Food (min)')\n",
        "ax2.set_ylabel('Flood (min)')\n",
        "for i, label in enumerate(labels):\n",
        "    ax2.annotate(label, (x[i], y[i]), textcoords=\"offset points\", xytext=(5, 5), ha='center')\n",
        "ax2.set_title('2D Scatter Plot with Marker Size')\n",
        "\n",
        "# Third panel: 2D scatter plot with color for the third dimension\n",
        "ax3 = fig.add_subplot(133)\n",
        "sc3 = ax3.scatter(x, y, c=z, cmap='viridis')  # use z to color the markers\n",
        "ax2.set_xlabel('Food (min)')\n",
        "ax2.set_ylabel('Flood (min)')\n",
        "for i, label in enumerate(labels):\n",
        "    ax3.annotate(label, (x[i], y[i]), textcoords=\"offset points\", xytext=(5, 5), ha='center')\n",
        "ax3.set_title('2D Scatter Plot with Color')\n",
        "plt.colorbar(sc3, ax=ax3, label='Environment (min)')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "ZfTAN6wPdb06"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "More dimensions are usually represented with a Parallel Axis plot:"
      ],
      "metadata": {
        "id": "ULFWhZiIe9Ut"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Combine the data into a single array\n",
        "neg_w = w # the direction os preference for all indicator is minimum, except for HP production (w). We add the. minus sign to match direction of preference\n",
        "data = np.vstack([x, y, z, neg_w]).T\n",
        "\n",
        "# Normalize the data to 0-1 range for each dimension.\n",
        "data_normalized = (data - data.min(axis=0)) / (data.max(axis=0) - data.min(axis=0))\n",
        "\n",
        "# Number of variables\n",
        "num_vars = data.shape[1]\n",
        "\n",
        "# Set up the plot\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "\n",
        "# Plot each data point\n",
        "for i in range(len(data_normalized)):\n",
        "    ax.plot(range(num_vars), data_normalized[i, :], marker='o', label=labels[i])\n",
        "    for j in range(num_vars):\n",
        "        ax.text(j, data_normalized[i, j], labels[i], ha='center', va='bottom')\n",
        "\n",
        "# Set the ticks and labels\n",
        "ax.set_xticks(range(num_vars))\n",
        "ax.set_xticklabels(labels)\n",
        "ax.set_xlim([0, num_vars - 1])\n",
        "\n",
        "# Add grid lines for better readability\n",
        "ax.grid(True)\n",
        "\n",
        "# Set axis labels\n",
        "ax.set_xlabel('Variables')\n",
        "ax.set_ylabel('Normalized Value (direction of preference down)')\n",
        "\n",
        "# Add a title\n",
        "plt.title('Parallel Coordinates Plot')\n",
        "\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "1-A6tBOTePqY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}